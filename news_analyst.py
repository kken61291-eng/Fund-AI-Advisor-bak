import requests
import json
import os
import re
import akshare as ak
import time
import random
import pandas as pd
from datetime import datetime
from utils import logger, retry, get_beijing_time

class NewsAnalyst:
    def __init__(self):
        self.api_key = os.getenv("LLM_API_KEY")
        self.base_url = os.getenv("LLM_BASE_URL")
        # æˆ˜æœ¯æ‰§è¡Œ (å¿«æ€è€ƒ): V3.2 - è´Ÿè´£ CGO/CRO/CIO å®æ—¶ä¿¡å·
        self.model_tactical = "Pro/deepseek-ai/DeepSeek-V3.2"      
        # æˆ˜ç•¥æ¨ç† (æ…¢æ€è€ƒ): R1 - è´Ÿè´£ å®è§‚å¤ç›˜/é€»è¾‘å®¡è®¡
        self.model_strategic = "Pro/deepseek-ai/DeepSeek-R1"   

        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

    def _clean_time(self, t_str):
        """ç»Ÿä¸€æ—¶é—´æ ¼å¼ä¸º MM-DD HH:MM"""
        try:
            if len(str(t_str)) >= 16:
                return str(t_str)[5:16]
            return str(t_str)
        except: return ""

    def _fetch_live_patch(self):
        """
        [7x24å…¨çƒè´¢ç»ç”µæŠ¥] - åŒæºæŠ“å– (EastMoney + CLS)
        """
        news_list = []
        
        # 1. ä¸œæ–¹è´¢å¯Œ
        try:
            df_em = ak.stock_telegraph_em()
            if df_em is not None and not df_em.empty:
                for i in range(min(50, len(df_em))):
                    title = str(df_em.iloc[i].get('title') or '')
                    content = str(df_em.iloc[i].get('content') or '')
                    t = self._clean_time(df_em.iloc[i].get('public_time'))
                    
                    if self._is_valid_news(title):
                        item_str = f"[{t}] [EM] {title}"
                        if len(content) > 10 and content != title:
                            item_str += f"\n   (æ‘˜è¦: {content[:300]})"
                        news_list.append(item_str)
        except Exception as e:
            logger.warning(f"Live EM fetch error: {e}")

        # 2. è´¢è”ç¤¾
        try:
            df_cls = ak.stock_telegraph_cls()
            if df_cls is not None and not df_cls.empty:
                for i in range(min(50, len(df_cls))):
                    title = str(df_cls.iloc[i].get('title') or '')
                    content = str(df_cls.iloc[i].get('content') or '')
                    raw_t = df_cls.iloc[i].get('ctime', df_cls.iloc[i].get('publish_time'))
                    
                    try:
                        if str(raw_t).isdigit():
                            dt = datetime.fromtimestamp(int(raw_t))
                            t = dt.strftime("%m-%d %H:%M")
                        else:
                            t = self._clean_time(raw_t)
                    except: t = ""

                    if not title and content: title = content[:30] + "..."

                    if self._is_valid_news(title):
                        item_str = f"[{t}] [CLS] {title}"
                        if len(content) > 10 and content != title:
                            item_str += f"\n   (æ‘˜è¦: {content[:300]})"
                        news_list.append(item_str)
        except Exception as e:
            logger.warning(f"Live CLS fetch error: {e}")

        return news_list

    def _is_valid_news(self, title):
        if not title: return False
        if len(title) < 2: return False
        return True

    def get_market_context(self, max_length=35000): 
        """
        [æ ¸å¿ƒé€»è¾‘] æ”¶é›†(Local+EM+CLS) -> å»é‡ -> æ’åº -> æˆªæ–­
        """
        news_candidates = []
        today_str = get_beijing_time().strftime("%Y-%m-%d")
        file_path = f"data_news/news_{today_str}.jsonl"
        
        # 1. ä¼˜å…ˆè¯»å–å®æ—¶ç”µæŠ¥ (åŒæº)
        live_news = self._fetch_live_patch()
        if live_news:
            news_candidates.extend(live_news)
            
        # 2. è¡¥å……æœ¬åœ°ç¼“å­˜çš„å†å²æ–°é—»
        if os.path.exists(file_path):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        try:
                            item = json.loads(line)
                            title = str(item.get('title', ''))
                            if not self._is_valid_news(title): continue
                                
                            t_str = self._clean_time(item.get('time', ''))
                            source = item.get('source', 'Local')
                            src_tag = "[EM]" if source == "EastMoney" else ("[CLS]" if source == "CLS" else "[Local]")
                            
                            content = str(item.get('content') or item.get('digest') or "")
                            
                            news_entry = f"[{t_str}] {src_tag} {title}"
                            if len(content) > 10:
                                news_entry += f"\n   (æ‘˜è¦: {content[:300]})"
                                
                            news_candidates.append(news_entry)
                        except: pass
            except Exception as e:
                logger.error(f"è¯»å–æ–°é—»ç¼“å­˜å¤±è´¥: {e}")
        
        # 3. å»é‡ (åŸºäºæ ‡é¢˜)
        unique_news = []
        seen = set()
        for n in news_candidates:
            try:
                title_part = n.split('] ', 2)[-1].split('\n')[0]
            except:
                title_part = n.split('\n')[0]
                
            if title_part not in seen:
                seen.add(title_part)
                unique_news.append(n)
        
        # 4. å¼ºåˆ¶å€’åº
        try:
            unique_news.sort(key=lambda x: x[:17], reverse=True)
        except: pass 
        
        # 5. æˆªæ–­
        final_list = []
        current_len = 0
        for news_item in unique_news:
            item_len = len(news_item)
            if current_len + item_len < max_length:
                final_list.append(news_item)
                current_len += item_len + 1 
            else:
                break
        
        final_text = "\n".join(final_list)
        return final_text if final_text else "ä»Šæ—¥æš‚æ— é‡å¤§æ–°é—»ã€‚"

    def _clean_json(self, text):
        try:
            text = re.sub(r'```json\s*', '', text)
            text = re.sub(r'```', '', text)
            text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)
            start = text.find('{')
            end = text.rfind('}')
            if start != -1 and end != -1:
                text = text[start:end+1]
            text = re.sub(r',\s*}', '}', text)
            text = re.sub(r',\s*]', ']', text)
            return text
        except: return "{}"
    
    def _clean_html(self, text):
        text = text.replace("```html", "").replace("```", "").strip()
        return text

    @retry(retries=1, delay=2)
    def analyze_fund_v5(self, fund_name, tech, macro, news, risk, strategy_type="core"):
        """
        [æˆ˜æœ¯å±‚] è”é‚¦æŠ•å§”ä¼š (V3.2) - å¼•å…¥ IC è§’è‰²çºªå¾‹è§„èŒƒ v2.0
        """
        fuse_level = risk['fuse_level']
        fuse_msg = risk['risk_msg']
        trend_score = tech.get('quant_score', 50)
        
        # [V15.20 æ”¹åŠ¨] æ¤å…¥ CGO/CRO/CIO è§’è‰²çºªå¾‹ä¸é“å¾‹
        prompt = f"""
        ã€ç³»ç»Ÿæ¶æ„ã€‘é¹ŠçŸ¥é£æŠ•å§”ä¼š (IC) | è§’è‰²çºªå¾‹è§„èŒƒ v2.0
        

        ã€æ ‡çš„ä¿¡æ¯ã€‘
        æ ‡çš„: {fund_name} (å±æ€§: {strategy_type})
        è¶‹åŠ¿å¼ºåº¦: {trend_score}/100 | ç†”æ–­çŠ¶æ€: Level{fuse_level} | ç¡¬çº¦æŸ: {fuse_msg}
        æŠ€æœ¯æŒ‡æ ‡: RSI={tech.get('rsi',50)} | MACD={tech.get('macd',{}).get('trend','-')}
        
        ã€å®æ—¶èˆ†æƒ… (EastMoney + CLS)ã€‘
        {str(news)[:25000]}

        ã€è§’è‰²çºªå¾‹ (Strict IC Protocols)ã€‘
        
        1. ğŸ» CRO (é˜²å®ˆåº•çº¿):
           - æ ¸å¿ƒ: ä¿æŠ¤æœ¬é‡‘ï¼Œå…³æ³¨ Tail Risk (å°¾éƒ¨é£é™©) å’Œ Correlation (ç›¸å…³æ€§)ã€‚
           - é“å¾‹ (No Generic Fear): ç¦æ­¢å°†â€œåœ°ç¼˜æ”¿æ²»â€ä½œä¸ºä¸‡èƒ½åˆ©ç©ºã€‚åœ°ç¼˜ç´§å¼ å¯¹è‚¡ç¥¨æ˜¯åˆ©ç©ºï¼Œä½†å¯¹é¿é™©èµ„äº§(é»„é‡‘/èƒ½æº)æ˜¯**æ ¸å¿ƒåˆ©å¥½**ã€‚
           - é“å¾‹ (Hedge over Liquidity): å½“å®è§‚é£é™©æé«˜æ—¶ï¼Œæ‹¥æœ‰**"æŒ‡æ ‡è±å…æƒ"**ã€‚å³ä½¿æµåŠ¨æ€§å·®ï¼Œä¹Ÿå¿…é¡»å»ºè®®é…ç½®å¯¹å†²(Hedge)ä»“ä½ï¼Œè€Œéæœºæ¢°æ‹’ç»ã€‚

        2. ğŸ¦Š CGO (è¿›æ”»é”‹çº¿):
           - æ ¸å¿ƒ: å¯»æ‰¾ Catalyst (å‚¬åŒ–å‰‚) å’Œ Momentum (åŠ¨é‡)ã€‚
           - é“å¾‹ (No Forced Correlation): ç¦æ­¢"å¼ºè¡Œå…³è”"ã€‚å¿…é¡»è¯æ˜æ–°é—»å¯¹è¯¥æ ‡çš„æœ‰ **Direct Causality** (ç›´æ¥è¥æ”¶/æˆæœ¬å½±å“)ã€‚ç¦æ­¢ AI-washing (ç”Ÿç¡¬è¹­AIçƒ­ç‚¹)ã€‚
           - é“å¾‹ (Volume Confirmation): æ‹’ç»ç¼©é‡ä¸Šæ¶¨ã€‚

        3. âš–ï¸ CIO (å†³ç­–ä¸­æ¢):
           - æ ¸å¿ƒ: è®¡ç®— Risk-Reward Ratio (ç›ˆäºæ¯”) ä¸ Position Sizing (ä»“ä½)ã€‚
           - é“å¾‹: å¿…é¡»ç»™å‡ºå…·ä½“çš„ä»“ä½è°ƒæ•´å»ºè®® (adjustment)ã€‚
           - è§†è§’: å¿…é¡»åŒ…å« **JPY (æ—¥å…ƒ)** æ±‡ç‡ç»´åº¦åŠæ—¥æœ¬åœ°ç¼˜è§†è§’çš„è€ƒé‡ã€‚

        ã€ä»»åŠ¡ã€‘
        ä»…åŸºäºæä¾›çš„æ•°æ®ï¼Œæ¨¡æ‹Ÿä¸Šè¿°ä¸‰ä½è§’è‰²çš„è¾©è®ºã€‚
        è‹¥ç†”æ–­ Level >= 2ï¼Œç›´æ¥æ‰§è¡Œé£æ§æ¸…ä»“é€»è¾‘ã€‚

        ã€è¾“å‡ºæ ¼å¼ã€‘
        {{
            "bull_view": "CGOè§‚ç‚¹ (èšç„¦èµ”ç‡/å‚¬åŒ–å‰‚/ç›´æ¥å› æœ)",
            "bear_view": "CROè§‚ç‚¹ (èšç„¦æ•å£/å¯¹å†²/æœ¬é‡‘å®‰å…¨/éé€šç”¨ææ…Œ)",
            "chairman_conclusion": "CIOæœ€ç»ˆè£å†³ (åŒ…å«æ—¥æœ¬è§†è§’/ç›ˆäºæ¯”è®¡ç®—)",
            "decision": "EXECUTE|REJECT|HOLD",
            "adjustment": -100 ~ 100 (å»ºè®®ä»“ä½è°ƒæ•´æ¯”ä¾‹)
        }}
        """
        
        payload = {
            "model": self.model_tactical,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.1,
            "max_tokens": 800,
            "response_format": {"type": "json_object"}
        }
        
        try:
            resp = requests.post(f"{self.base_url}/chat/completions", headers=self.headers, json=payload, timeout=90)
            if resp.status_code != 200:
                return self._get_fallback_result()
            
            content = resp.json()['choices'][0]['message']['content']
            result = json.loads(self._clean_json(content))
            
            try: result['adjustment'] = int(result.get('adjustment', 0))
            except: result['adjustment'] = 0

            # å¼ºåˆ¶æ‰§è¡Œç†”æ–­é€»è¾‘
            if fuse_level >= 2:
                result['decision'] = 'REJECT'
                result['adjustment'] = -30
                result['chairman_conclusion'] = f'[ç³»ç»Ÿç†”æ–­] {fuse_msg} - å¼ºåˆ¶æ‰§è¡Œé£æ§çºªå¾‹ã€‚'

            return result
        except Exception as e:
            logger.error(f"AI Analysis Failed {fund_name}: {e}")
            return self._get_fallback_result()

    def _get_fallback_result(self):
        return {"bull_view": "Error", "bear_view": "Error", "chairman_conclusion": "Offline", "decision": "HOLD", "adjustment": 0}

    @retry(retries=2, delay=5)
    def review_report(self, report_text, macro_str):
        """
        [æˆ˜ç•¥å±‚] CIO å¤ç›˜ (R1) - ç­–ç•¥ä¸€è‡´æ€§ä¸å®è§‚å®šè°ƒ
        """
        current_date = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
        
        # [V15.20 æ”¹åŠ¨] å¼•å…¥ CIO å®è§‚å®šè°ƒçºªå¾‹ä¸ç­–ç•¥ä¸€è‡´æ€§æ£€æŸ¥
        prompt = f"""
        ã€ç³»ç»Ÿè§’è‰²ã€‘é¹ŠçŸ¥é£ CIO (Chief Investment Officer) | æˆ˜ç•¥å¤ç›˜
        æ—¥æœŸ: {current_date} 

        ã€è¾“å…¥æ•°æ®ã€‘
        1. å®è§‚ç¯å¢ƒ (News Flow): {macro_str[:2500]}
        2. äº¤æ˜“å†³ç­– (IC Decisions): {report_text[:3000]}

        ã€æˆ˜ç•¥ä»»åŠ¡ã€‘
        è¯·æ’°å†™ã€Šæ¯æ—¥æŠ•èµ„å¤ç›˜å¤‡å¿˜å½•ã€‹ï¼Œé‡ç‚¹æ‰§è¡Œä»¥ä¸‹çºªå¾‹ï¼š

        1. å®è§‚å®šè°ƒ (Macro Regime):
           - å®šä¹‰ä»Šæ—¥å¸‚åœºæƒ…ç»ªï¼šææ…Œ(Panic) / è´ªå©ª(Greed) / åˆ†æ­§(Divergence)ã€‚
           - å¿…é¡»è¯†åˆ«ä¸»è¦çŸ›ç›¾ï¼ˆå¦‚ï¼šåœ°ç¼˜æ”¿æ²» vs æ”¿ç­–å®½æ¾ï¼‰ã€‚

        2. ç­–ç•¥ä¸€è‡´æ€§æ£€æŸ¥ (Strategy Consistency Check):
           - å®¡æŸ¥æŠ•å§”ä¼šçš„æ“ä½œæ˜¯å¦ç²¾ç¥åˆ†è£‚ï¼Ÿ
           - ä¾‹å¦‚ï¼šå¦‚æœå®è§‚å®šè°ƒä¸º"æåº¦ææ…Œ"ï¼Œä½†å†³ç­–å´åœ¨ä¹°å…¥é«˜é£é™©å°ç›˜è‚¡ï¼Œè¯·ä¸¥å‰æŒ‡å‡ºã€‚
           - æ£€æŸ¥æ˜¯å¦å¿½è§†äº†æ—¥æœ¬è§†è§’ï¼ˆå¦‚æ—¥å…ƒæ±‡ç‡é£é™©ï¼‰ã€‚

        3. é£é™©æç¤º (Risk Radar):
           - æŒ‡å‡ºæ•°æ®ä¸­éšå«çš„ Tail Risk (å°¾éƒ¨é£é™©)ã€‚
           - é‡ç‚¹å…³æ³¨æµåŠ¨æ€§é™·é˜±å’Œç›¸å…³æ€§å´©å¡Œã€‚

        ã€è¾“å‡ºã€‘HTMLæ ¼å¼ CIO å¤‡å¿˜å½•ã€‚
        """
        return self._call_r1(prompt)

    @retry(retries=2, delay=5)
    def advisor_review(self, report_text, macro_str):
        """
        [å®¡è®¡å±‚] Red Team é¡¾é—® (R1) - é€»è¾‘é»‘å®¢ä¸å‹åŠ›æµ‹è¯•
        """
        current_date = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
        
        # [V15.20 æ”¹åŠ¨] å¼•å…¥ Red Team é€»è¾‘é»‘å®¢å®¡è®¡
        prompt = f"""
        ã€ç³»ç»Ÿè§’è‰²ã€‘é¹ŠçŸ¥é£ Red Team | ç‹¬ç«‹é€»è¾‘é»‘å®¢ (Logic Hacker)
        æ—¥æœŸ: {current_date}

        ã€è¾“å…¥æ•°æ®ã€‘
        å®è§‚: {macro_str[:2500]} | äº¤æ˜“: {report_text[:3000]}

        ã€å®¡è®¡ä»»åŠ¡ã€‘
        ä½œä¸º"æ‰¾èŒ¬ä¸“å®¶"ï¼Œè¯·æ— æƒ…åœ°æ”»å‡» CIO çš„å†³ç­–é€»è¾‘ã€‚å¯»æ‰¾ Blind Spot (ç›²åŒº) å’Œ Overfitting (è¿‡æ‹Ÿåˆ)ã€‚

        ã€äº”ç»´å‹åŠ›æµ‹è¯• (Stress Test)ã€‘
        Q1: å†³ç­–æ¿€è¿›æ€§å®¡è®¡ (æ˜¯å¦åœ¨æ¥é£åˆ€?)
        Q2: å®è§‚é€»è¾‘æ¼æ´ (æ˜¯å¦ç”¨åŒæ ·çš„å®è§‚ç†ç”±è§£é‡Šå®Œå…¨ç›¸åçš„äº¤æ˜“?)
        Q3: ä»“ä½åˆç†æ€§ (æ˜¯å¦å¤„äº"è£¸å¥”"çŠ¶æ€ï¼Œç¼ºä¹ Hedging?)
        Q4: è¶‹åŠ¿èƒŒç¦»é£é™© (æ˜¯å¦åœ¨å¯¹æŠ—ä¸å¯é€†è½¬çš„è¶‹åŠ¿?)
        Q5: æƒ…ç»ªåŒ–äº¤æ˜“æ£€æµ‹ (CGO æ˜¯å¦å­˜åœ¨å¼ºè¡Œå…³è”/AI-washing?)

        ã€è¾“å‡ºã€‘HTMLæ ¼å¼é£æ§å®¡è®¡æŠ¥å‘Šï¼Œå¿…é¡»åŒ…å«"å…³é”®æ¼æ´"å’Œ"é£é™©è¯„çº§"ã€‚
        """
        return self._call_r1(prompt)

    def _call_r1(self, prompt):
        payload = {
            "model": self.model_strategic, 
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": 4000,
            "temperature": 0.3 
        }
        try:
            resp = requests.post(f"{self.base_url}/chat/completions", headers=self.headers, json=payload, timeout=180)
            content = resp.json()['choices'][0]['message']['content']
            return self._clean_html(content)
        except:
            return "<p>åˆ†æç”Ÿæˆä¸­...</p>"
