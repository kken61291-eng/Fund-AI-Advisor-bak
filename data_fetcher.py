import akshare as ak
import pandas as pd
import time
import random
import os
import yaml
from datetime import datetime, time as dt_time
# æ³¨æ„ï¼šå¦‚æœ utils æ¨¡å—ä¸å­˜åœ¨ï¼Œéœ€ç¡®ä¿ get_beijing_time èƒ½æ­£å¸¸å·¥ä½œï¼Œè¿™é‡Œè¡¥å……ä¸€ä¸ªç®€æ˜“å®ç°ï¼ˆå¯æ ¹æ®å®é™…æƒ…å†µæ›¿æ¢ï¼‰
import logging

# ===================== ä¸´æ—¶è¡¥å…… utils æ¨¡å—ç¼ºå¤±çš„éƒ¨åˆ†ï¼ˆå¦‚æœéœ€è¦ï¼‰ =====================
# å¦‚æœä½ çš„ç¯å¢ƒä¸­å·²æœ‰ utils æ¨¡å—ï¼Œå¯åˆ é™¤è¿™éƒ¨åˆ†
def get_beijing_time():
    """è·å–åŒ—äº¬æ—¶é—´ï¼ˆä¸œå…«åŒºï¼‰"""
    from datetime import timezone, timedelta
    return datetime.now(timezone(timedelta(hours=8)))

# ç®€æ˜“æ—¥å¿—é…ç½®
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def retry(retries=3, delay=5):
    """ç®€æ˜“é‡è¯•è£…é¥°å™¨"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            for i in range(retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if i == retries - 1:
                        raise e
                    time.sleep(delay)
            return None
        return wrapper
    return decorator
# ====================================================================================

class DataFetcher:
    def __init__(self):
        # [V15.13] æœ¬åœ°æ•°æ®ä»“åº“é…ç½®
        # æ³¨æ„ï¼šè¿™é‡Œä¿æŒæ‚¨åŸæœ‰çš„ data_cache ç›®å½•åç§°
        self.DATA_DIR = "data_cache"
        if not os.path.exists(self.DATA_DIR):
            os.makedirs(self.DATA_DIR)
            
        self.user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15"
        ]

    def _verify_data_freshness(self, df, fund_code, source_name):
        """æ•°æ®æ–°é²œåº¦å®¡è®¡ (é€šç”¨)"""
        if df is None or df.empty: return
        
        try:
            last_date = pd.to_datetime(df.index[-1]).date()
            now_bj = get_beijing_time()
            today_date = now_bj.date()
            is_trading_time = (dt_time(9, 30) <= now_bj.time() <= dt_time(15, 0))
            
            log_prefix = f"ğŸ“… [{source_name}] {fund_code} æœ€æ–°æ—¥æœŸ: {last_date}"
            
            if last_date == today_date:
                logger.info(f"{log_prefix} | âœ… æ•°æ®å·²æ›´æ–°è‡³ä»Šæ—¥")
            elif last_date < today_date:
                days_gap = (today_date - last_date).days
                # å¦‚æœæ˜¯äº¤æ˜“æ—¶é—´ä¸”æ•°æ®æ»åï¼Œæ‰è­¦å‘Š
                if is_trading_time and days_gap >= 1:
                    logger.warning(f"{log_prefix} | âš ï¸ æ•°æ®æ»å {days_gap} å¤© (è¯·è¿è¡Œçˆ¬è™«æ›´æ–°)")
                else:
                    logger.info(f"{log_prefix} | â¸ï¸ å†å²æ•°æ®å°±ç»ª")
        except Exception as e:
            logger.warning(f"å®¡è®¡æ•°æ®æ–°é²œåº¦å¤±è´¥: {e}")

    @retry(retries=3, delay=5)
    def _fetch_from_network(self, fund_code):
        """
        [ç§æœ‰æ–¹æ³•] çº¯è”ç½‘è·å–æ•°æ® (ä¸œè´¢ -> æ–°æµª -> è…¾è®¯)
        ä¾› update_cache è°ƒç”¨
        """
        # 1. ä¸œè´¢ (EastMoney) - ä¼˜å…ˆæ•°æ®æº
        try:
            # æ¨¡æ‹Ÿéšæœºå»¶æ—¶ (åŸºç¡€å»¶æ—¶)
            time.sleep(random.uniform(1.0, 2.0)) 
            df = ak.fund_etf_hist_em(symbol=fund_code, period="daily", start_date="20200101", end_date="20500101", adjust="qfq")
            rename_map = {'æ—¥æœŸ':'date', 'å¼€ç›˜':'open', 'æ”¶ç›˜':'close', 'æœ€é«˜':'high', 'æœ€ä½':'low', 'æˆäº¤é‡':'volume'}
            df.rename(columns=rename_map, inplace=True)
            df['date'] = pd.to_datetime(df['date'])
            df.set_index('date', inplace=True)
            # ========== æ–°å¢ï¼šæ·»åŠ æ•°æ®æŠ“å–æ—¶é—´å­—æ®µ ==========
            # è·å–å½“å‰åŒ—äº¬æ—¶é—´ï¼ˆç²¾ç¡®åˆ°ç§’ï¼‰ï¼Œä½œä¸ºæŠ“å–æ—¶é—´æˆ³
            fetch_time = get_beijing_time().strftime("%Y-%m-%d %H:%M:%S")
            df['fetch_time'] = fetch_time  # ä¸ºæ¯æ¡æ•°æ®æ·»åŠ æŠ“å–æ—¶é—´
            # ==============================================
            if not df.empty: return df, "ä¸œè´¢"
        except Exception as e:
            logger.error(f"ä¸œè´¢æ•°æ®æºå¼‚å¸¸: {e}")
            pass

        # 2. æ–°æµª (Sina)
        try:
            time.sleep(1)
            df = ak.fund_etf_hist_sina(symbol=fund_code)
            if df.index.name in ['date', 'æ—¥æœŸ']: df = df.reset_index()
            # ç®€å•çš„åˆ—å¯¹é½é€»è¾‘
            if len(df.columns) >= 6:
                df.columns = ['date', 'open', 'high', 'low', 'close', 'volume'] + list(df.columns[6:])
            if 'date' in df.columns:
                df['date'] = pd.to_datetime(df['date'])
                df.set_index('date', inplace=True)
                # ç±»å‹æ¸…æ´—
                for col in ['open', 'high', 'low', 'close', 'volume']:
                    if col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce')
                # ========== æ–°å¢ï¼šæ·»åŠ æ•°æ®æŠ“å–æ—¶é—´å­—æ®µ ==========
                fetch_time = get_beijing_time().strftime("%Y-%m-%d %H:%M:%S")
                df['fetch_time'] = fetch_time
                # ==============================================
                return df, "æ–°æµª"
        except Exception as e:
            logger.error(f"æ–°æµªæ•°æ®æºå¼‚å¸¸: {e}")
            pass

        # 3. è…¾è®¯ (Tencent)
        try:
            time.sleep(1)
            prefix = 'sh' if fund_code.startswith('5') else ('sz' if fund_code.startswith('1') else '')
            if prefix:
                df = ak.stock_zh_a_hist_tx(symbol=f"{prefix}{fund_code}", start_date="20200101", adjust="qfq")
                rename_map = {'æ—¥æœŸ':'date', 'å¼€ç›˜':'open', 'æ”¶ç›˜':'close', 'æœ€é«˜':'high', 'æœ€ä½':'low', 'æˆäº¤é‡':'volume'}
                df.rename(columns=rename_map, inplace=True)
                df['date'] = pd.to_datetime(df['date'])
                df.set_index('date', inplace=True)
                # ========== æ–°å¢ï¼šæ·»åŠ æ•°æ®æŠ“å–æ—¶é—´å­—æ®µ ==========
                fetch_time = get_beijing_time().strftime("%Y-%m-%d %H:%M:%S")
                df['fetch_time'] = fetch_time
                # ==============================================
                if not df.empty: return df, "è…¾è®¯"
        except Exception as e:
            logger.error(f"è…¾è®¯æ•°æ®æºå¼‚å¸¸: {e}")
            pass
        
        return None, None

    def update_cache(self, fund_code):
        """
        [çˆ¬è™«ä¸“ç”¨] è”ç½‘ä¸‹è½½æ•°æ®å¹¶ä¿å­˜åˆ°æœ¬åœ° CSV
        """
        df, source = self._fetch_from_network(fund_code)
        if df is not None and not df.empty:
            file_path = os.path.join(self.DATA_DIR, f"{fund_code}.csv")
            df.to_csv(file_path)
            logger.info(f"ğŸ’¾ [{source}] {fund_code} æ•°æ®å·²ä¿å­˜è‡³ {file_path} (å«æŠ“å–æ—¶é—´å­—æ®µ fetch_time)")
            
            # [æ–°å¢ä¼˜åŒ–] å¦‚æœæ˜¯ä¸œè´¢æ•°æ®ï¼Œå¼ºåˆ¶ç­‰å¾… 40 ç§’ï¼Œé˜²æ­¢æ¥å£å°ç¦
            # è¿™æ ·å¯ä»¥æœ€å¤§ç¨‹åº¦ä¿è¯åç»­çš„åŸºé‡‘ä¹Ÿèƒ½ç”¨åˆ°ä¸œè´¢æ•°æ®
            if source == "ä¸œè´¢":
                logger.info("â³ [ä¸œè´¢] è§¦å‘é¢‘ç‡ä¿æŠ¤æœºåˆ¶ï¼Œç­‰å¾… 40 ç§’...")
                time.sleep(40)
                
            return True
        else:
            logger.error(f"âŒ {fund_code} æ‰€æœ‰æ•°æ®æº(ä¸œè´¢/æ–°æµª/è…¾è®¯)å‡è·å–å¤±è´¥")
            return False

    def get_fund_history(self, fund_code, days=250):
        """
        [ä¸»ç¨‹åºä¸“ç”¨] åªè¯»æ¨¡å¼ï¼šç›´æ¥ä»æœ¬åœ° CSV è¯»å–æ•°æ®
        """
        file_path = os.path.join(self.DATA_DIR, f"{fund_code}.csv")
        
        if not os.path.exists(file_path):
            # è¿™é‡Œçš„æç¤ºå¼•å¯¼ç”¨æˆ·å»è¿è¡Œçˆ¬è™«
            logger.warning(f"âš ï¸ æœ¬åœ°ç¼“å­˜ç¼ºå¤±: {fund_code}ï¼Œè¯·ç­‰å¾… GitHub Action çˆ¬è™«è¿è¡Œ")
            return None
            
        try:
            # è¯»å– CSV
            df = pd.read_csv(file_path)
            
            # è¿˜åŸç´¢å¼•å’Œæ•°æ®ç±»å‹
            if 'date' in df.columns:
                df['date'] = pd.to_datetime(df['date'])
                df.set_index('date', inplace=True)
            
            # ========== æ–°å¢ï¼šè§£ææŠ“å–æ—¶é—´å­—æ®µä¸º datetime ç±»å‹ ==========
            if 'fetch_time' in df.columns:
                df['fetch_time'] = pd.to_datetime(df['fetch_time'])
            # ===========================================================
            
            self._verify_data_freshness(df, fund_code, "æœ¬åœ°ç¼“å­˜")
            return df
            
        except Exception as e:
            logger.error(f"âŒ è¯»å–æœ¬åœ°ç¼“å­˜å¤±è´¥ {fund_code}: {e}")
            return None

# ==========================================
# [æ–°å¢] ç‹¬ç«‹è¿è¡Œå…¥å£ (è®©æ­¤è„šæœ¬å˜èº«çˆ¬è™«)
# ==========================================
if __name__ == "__main__":
    print("ğŸš€ [DataFetcher] å¯åŠ¨å¤šæºè¡Œæƒ…æŠ“å– (V15.15 Full Mode)...")
    
    # 1. ç®€æ˜“åŠ è½½ Config
    def load_config_local():
        try:
            with open('config.yaml', 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except:
            return {}

    cfg = load_config_local()
    funds = cfg.get('funds', [])
    
    if not funds:
        print("âš ï¸ æœªæ‰¾åˆ°åŸºé‡‘åˆ—è¡¨ï¼Œè¯·æ£€æŸ¥ config.yaml")
        exit()

    # 2. åˆå§‹åŒ–
    fetcher = DataFetcher()
    success_count = 0
    
    # 3. å¾ªç¯æ›´æ–°
    for fund in funds:
        code = fund.get('code')
        name = fund.get('name')
        print(f"ğŸ”„ æ›´æ–°: {name} ({code})...")
        
        try:
            # è°ƒç”¨ update_cache è¿›è¡Œè”ç½‘ä¸‹è½½
            # æ³¨æ„ï¼šupdate_cache å†…éƒ¨ç°åœ¨åŒ…å«äº†é’ˆå¯¹ä¸œè´¢çš„ 50s ç­‰å¾…é€»è¾‘
            if fetcher.update_cache(code):
                success_count += 1
            
            # åŸºç¡€é—´éš”ï¼Œé¿å…éä¸œè´¢æºæ—¶è¯·æ±‚è¿‡å¿«
            # å¦‚æœåˆšåˆšè§¦å‘äº†ä¸œè´¢çš„50sç­‰å¾…ï¼Œè¿™é‡Œé¢å¤–å¤šç¡1-2sä¹Ÿæ— å¦¨
            time.sleep(random.uniform(1.0, 2.0))
            
        except Exception as e:
            print(f"âŒ æ›´æ–°å¼‚å¸¸ {name}: {e}")
            
    print(f"ğŸ è¡Œæƒ…æ›´æ–°å®Œæˆ: {success_count}/{len(funds)} (å·²æ·»åŠ  fetch_time æ—¶é—´å­—æ®µ)")
